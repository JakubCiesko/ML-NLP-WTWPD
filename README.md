# Cross-Language Word Embedding Alignment
## Poster / Project for ML in NLP

This project implements a domain-adversarial approach to learn linear mappings between two sets of word embeddings from different languages without cross-lingual supervision. By refining these mappings using Procrustes analysis and enhancing translation accuracy with Cross-Domain Similarity Local Scaling (CSLS), the method addresses challenges in word translation and hubness in high-dimensional spaces. The resulting framework improves the reliability of nearest neighbor matching, facilitating better word translation across languages.
